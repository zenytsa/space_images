# Реконструкция изображений с плоского дифракционного объектива космического базирования


## 1 Немного истории

__Камера обскура - первый девайс для получения изображений__

Опыт использования различных устройств для создания реальных изображений нашего мира уходит очень далеко. Камера обскура – самое простое, но от этого не менее интересное устройство. Считают, его использовали некоторые художники для создания фотореалистичных картин еще в 15 веке. Процесс такой работы показан на рисунке 1.1.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.1.jpeg" width="50%" title="Камера обскура"/>
  
  Рисунок 1.1 –  Камера обскура
</div>

Часто приводят в качестве примера картину голландского художника Яна ван Эйка «Портрет четы Арнольфини» (1434 г.). Мы его тоже приведем на рисунке 1.2. Очень знакомые лица.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.2.jpg" width="50%" title="Картина Яна ван Эйка «Портрет четы Арнольфини» (1434 г.)"/>
  
  Рисунок 1.2 – Картина Яна ван Эйка «Портрет четы Арнольфини» (1434 г.)
</div>

Для своего времени эта картина отличалась невероятной детализацией. Зеркало, в котором отражается вся комната, и металлический канделябр сложной формы часто печатаются отдельными фрагментами как доказательство виртуозности мастера. Посмотрите на рисунок 1.3. Зеркало выпуклое, блики на элементах показывают, что они покрыты лаком. Четки из стекла. Такая реалистичность достигается точнейшей передачей цвета и светотени. Но на глаз сделать такую работу почти невозможно, так как блики меняются, стоит лишь двинуть головой или перевести взгляд.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.3.jpg" width="50%" title="Фрагмент картины с очень высокой детализацией изображения"/>
  
  Рисунок 1.3 – Фрагмент картины с очень высокой детализацией изображения
</div>

__Стеклянные линзы и первые фотоаппараты__

С появлением стеклянных линз стало все гораздо интереснее… и сложнее. Фотография завладела умами многих энтузиастов. На рисунке 1.4 показана схема и внешний вид одного из самых ранних фотоаппаратов. Принцип работы точно такой же как и у «камера обскура». В чем преимущество линзой над отверстием камеры обскура? Попадает больше света, а именно он нужен для химической реакции, которая позволяет регистрировать изображение на носителе.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.4(a).jpg" width="25%" title="Схема простейшего фотоаппарата с однолинзовым объективом"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.4(b).jpg" width="25%" title="Изображение простейшего фотоаппарата"/>
  
  Рисунок 1.4 – Простейший фотоаппарат с однолинзовым объективом
</div>

Первые фотографии были далеки от идеала. Требовали большого времени регистрации изображения из-за несовершенства технологии. Но постоянная работа огромного количества людей над увлекательной задачей фотографирования давала свои плоды. Процесс стал быстрее, качество изображений росло. На рисунке 1.5 представлены две известные фотографии. Изображение, снятое Жозефом Нисефором Ньепсом и известное как «Вид из окна в Ле Гра», было создано в 1826 году с помощью камеры-обскуры (даже пока без использования линзы) на пластинке, покрытой тонким слоем битума. На втором изображении реконструкция и оригинал первого селфи за авторством Роберта Корнелиуса. Вот он уже точно использовал фотоаппарат с линзовым объективом. 1839 год.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.5(a).jpg" width="25%" title="Первая фотография: Вид из окна в Ле Гра"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.5(b).jpg" width="25%" title="Первый фотоавтопортрет за авторством Роберта Корнелиуса"/>
  
  Рисунок 1.5 – Самые первые: первая фотография вообще и первый фотопортрет
</div>

Несмотря на то, что до появления возможности получать цветные изображения было еще очень далеко, российский изобретатель Прокудин-Горский придумал, как можно сохранить информацию о цвете. Три фотографии через три цветных фильтра. Даже сейчас смотрится очень круто. А до изобретения цветной пленки на тот момент было еще 25 лет. На рисунке 1.6 мы привели примеры того, как выглядели оригиналы фотографий и результаты восстановления таких изображений.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.6(a).jpg" width="50%" title="Восстановление из трех фото одного цветного"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.6(b).jpg" width="50%" title="Восстановленная фотография Эмира Бухарского (1911 г.)"/>
  
  Рисунок 1.6 – Фотографии сделанные Прокудиным-Горским: восстановление из трех фото одного цветного и восстановленная фотография Эмира Бухарского (1911 г.)
</div>

__Современные объективы__

Как и любая технология, объективы фотоаппаратов стали развиваться, усложняться и эволюционировать. Теперь это могут быть очень сложные, тяжелые и дорогие устройства, способные прекрасно решать возложенную на них задачу – собирать нужное количество света и фокусировать его в нужное место. На рисунке 1.7 показан один из современных объективов в разрезе и один из самых (но не самый) тяжелых серийных телеобъективов.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.7(a).jpg" width="25%" title="Разрез объектива"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.7(b).jpg" width="25%" title="Современный телеобъектив"/>
  
  Рисунок 1.7 – Современные фотообъективы. Разрез объектива. Телеобъектив
</div>

И даже объективы в мобильных устройствах являются вершиной технологий. Они маленькие и сложные. На рисунке 1.8 показано из скольких элементов может состоять объектив мобильной камеры.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.8.jpg" width="50%" title="Из чего состоит камера мобильного телефона"/>
  
  Рисунок 1.8 – Мобильное фото. Из чего состоит камера мобильного телефона
</div>

__Дифракционная оптика__

Несколько десятилетий назад с появлением серьезной вычислительной техники появилась возможность рассчитывать поведение света при прохождении через сложные поверхности на прозрачных элементах. Так началась история дифракционной оптики. На рисунке 1.9 примерный вид получаемого элемента.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.9.jpg" width="50%" title="Дифракционный элемент"/>
  
  Рисунок 1.9 – Дифракционный элемент
</div>

Эти сложные поверхности могут преломлять свет так, как нужно нам. При этом высота рельефа может быть всего 10 мкм. Значит, мы можем создать дифракционный элемент, который будет работать как линза и быть при этом очень тонким (и легким). Хм… Плоская линза. Где-то это уже было. Действительно, есть линза Френеля (рисунок 1.10). Дифракционная линза по своей идее очень похожа на линзу Френеля, только тоньше, точнее, НАМНОГО тоньше! На рисунке видно как на круглом стекле нанесены «окружности». Эти окружности высотой всего несколько микрометров. Они и есть наша линза. Если захотеть можно такой элемент создать на очень тонком стекле или даже на плёнке.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.10(a).jpg" width="50%" title="Схема получения линзы Френеля"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.10(b).jpg" width="50%" title="Дифракционная линза"/>
  
  Рисунок  1.10 – Линза Френеля. Рельеф дифракционной линзы
</div>

Итак, у нас есть линза. Но работает она не совсем так как привычные нам стеклянные линзы. Из-за того, что все происходит на поверхностях с очень низким, сравнимым с длиной волны света рельефом, начинают проявляться другие эффекты.

1)	Дифракционный оптический элемент (ДОЭ) рассчитывается для точного значения длины волны. Так, например, для лазерного излучения, которое имеет одну длину волны, дифракционная линза работает идеально — фокусирует такой пучок в нужной точке пространства.
Но видимый свет включает в себя множество длин волн. Можно представить обычный свет, отраженный от какого-то предмета, как множество лазерных пучков, каждый из которых обладает своей длиной волны и своей интенсивностью. Многие из вас и так поняли, что речь идет о спектре света. Так вот, дифракционная линза будет каждый пучок, отличающийся по длине волны от расчётного, фокусировать немного в другое место, ближе к линзе или дальше. При этом на изображении, которое мы получаем дифракционной линзой каждая точка будет выглядеть как немного размытое пятно. И сила такого размытия неодинакова и зависит от спектра света.

2)	Кроме этого, есть эффект, выглядящий на изображениях как ореол, накладывающийся на другие объекты. Этот ореол обусловлен перераспределением энергии при фокусировке.

На рисунке 1.11 один пример изображения, снятого на дифракционную линзу. На рисунке 1.12 изображение, полученное через обычный объектив, с более близкого расстояния и с другого ракурса.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.11.jpg" width="50%" title="Изображение, полученное плоским дифракционным объективом"/>
  
  Рисунок 1.11 – Изображение, полученное плоским дифракционным объективом
</div>

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.12.jpg" width="50%" title="Сцена снятая обычным фотоаппаратом"/>
  
  Рисунок 1.12 – Сцена снятая обычным фотоаппаратом
</div>

И тут возникает вопрос, а как же бороться с такими искажениями? Неужели не получится заменить обычную толстую линзу на дифракционную? Можно сделать такое изображение полезным, хотя бы буквы различить? Можно! На рисунке 1.13 пример того, что можно вытащить из снимка.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/1.13.jpg" width="50%" title="Результат реконструкции изображения полученного дифракционным объективом"/>
  
  Рисунок 1.13 – Результат реконструкции изображения, полученного дифракционным объективом
</div>

Проводить испытания в лаборатории, где идеальные условия, тепло и сухо, в какой-то момент стало скучно. Всегда было интересно посмотреть, как оно вживую может работать, на максималках! Мы решили отправить наш объектив в космос.

## 2.	Применение дифракционной оптики на спутнике

Чтобы проверить, как работает наш объектив, нам нужен был спутник. Такой спутник решили запустить ребята из Высшей Школы Экономики. Спутник в формате CubeSat 3U обладает небольшими размерами 10×10×30 см, но нам много места пока и не было нужно. Был разработан и изготовлен корпус для нашего объектива методом трехмерной печати из порошкового металла (рисунок 2.1).

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/2.1.jpg" width="50%" title="Корпус объектива"/>
  
  Рисунок 2.1 - Корпус объектива
</div>

В корпус мы установили дифракционную линзу и цифровую матрицу, и команда из ВШЭ поместили корпус в спутник (рисунок 2.2).

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/2.2.jpg" width="50%" title="Спутник CubeSat 3U"/>
  
  Рисунок 2.2 - Спутник CubeSat 3U
</div>

21 марта 2021 года спутник был успешно выведен на расчетную орбиту и началась работа. Настройка режимов съемки, передача на Землю несжатых изображений, работа по улучшению изображений, анализ ошибок и переобучение нейронных сетей. Работа и сейчас ведется постоянно. На рисунке 2.3 первое несжатое полноразмерное изображение с нашего объектива, которое мы получили и с которым начали работать.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/2.3.jpg" width="50%" title="Фрагмент изображения, полученного плоским дифракционным объективом со спутника"/>
  
  Рисунок 2.3 - Фрагмент изображения, полученного плоским дифракционным объективом
</div>

Задача, которую мы решаем — получить изображение с разрешающей способностью на поверхности не хуже 100 метров на 1 пиксель. А какими способами можно улучшить полученные снимки мы подробно опишем дальше. Это можно сделать при помощи графического редактора, можно использовать программную реконструкцию, или использовать нейронные сети.

## 3 Улучшение изображений в графических редакторах
Давайте посмотрим на исходное изображение на рисунке 3.1.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.1.jpg" width="50%" title="Исходное изображение"/>
  
  Рисунок 3.1 – Исходное изображение
</div>

На изображении часть побережья. Что же с ним не так? Изображение недостаточно контрастно и довольно сильно размыто. Всё, как мы любим! Повысить резкость и увеличить контраст можно с помощью графических редакторов (Gimp, Photoshop). Все графические редакторы предоставляют неплохой набор инструментов. Возьмём Adobe Photoshop просто для примера.
Попробуем поработать с контрастностью. Глазу приятнее, когда изображение сбалансировано по свету, присутствуют и темные и светлые части. Для начала нужно выровнять гистограмму изображения. За это отвечает инструмент Кривые (Изображение → Коррекция → Кривые) рисунок 3.2.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.2(a).jpg" width="25%" title="Панель инструмента Кривые"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.2(b).jpg" width="25%" title="Вид исходного изображения"/>
  
  Рисунок 3.2 – Инструмент Кривые
</div>

Выравниваем гистограмму и делаем S-кривую с небольшой кривизной, для этого нам хватит всего четырёх точек. Две точки зафиксируют места, где на изображении уже нет информации — самые яркие (левая часть гистограммы) и самые тёмные (правая часть гистограммы). Самая левая поставленная на кривой точка у нас отвечает за белый цвет, самая правая за черный. Две внутренние точки задают цвета которые на изображении будут наиболее различимыми. На рисунке 3.3 показано, как такие изменения влияют на изображение.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.3(a).jpg" width="25%" title="Панель инструмента Кривые с внесенными изменениями"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.3(b).jpg" width="25%" title="Результат изменения"/>
  
  Рисунок 3.3  Изменение изображения за счет выравнивания гистограммы
</div>

Стало гораздо приятнее глазу. Но осталось то, что заметно портит ощущение от изображения — шум, мелкие частые точки, похожие на пыль. Для устранения высокочастотного шума (а мелкие частые точки это именно такой шум) применяем размытие по Гауссу (Фильтр → Размытие → Размытие по Гауссу...) с радиусом 1,6 пикселей. При этом все будет выглядеть, как на рисунке 3.4.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.4(a).jpg" width="25%" title="Панель инструмента Размытие"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.4(b).jpg" width="25%" title="Результат изменения"/>
  
  Рисунок 3.4 – Размытие против шума
</div>

Теперь было бы неплохо увеличить чёткость (она же резкость) границ предметов на изображении. Инструментом Контурная резкость (Фильтр → Усиление резкости → Контурная резкость...) повышаем резкость на границах светлых и тёмных участков (рисунок 3.5).

<div align="center">
  <img src="https://github.com/zenytsa/SupportImages/blob/main/3.5(a).jpg" width="25%" title="Панель инструмента Усиление резкости"/>
  <img src="https://github.com/zenytsa/SupportImages/blob/main/3.5(b).jpg" width="25%" title="Результат изменения"/>
  
  Рисунок 3.5 - Улучшение резкости границ
</div>

А теперь посмотрим, что было в самом начале и что получилось в результате (рисунок 3.6). Необходимо убедиться, что важная информация сохранилась. При неудовлетворительном результате нужно подобрать чуть другие параметры фильтров.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.6(a).jpg" width="25%" title="Исходное изображение"/>
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/3.6(b).jpg" width="25%" title="Результат наших манипуляций"/>
  
  Рисунок 3.6 – Сравнение исходного изображения и результата
</div>

Неплохо получилось, но работа в графическом редакторе хоть и позволяет все делать на глаз, для стабильного результата требует большого опыта работы. Поэтому мы используем графический редактор только для того, чтобы быстро оценить картинку или подготовить её для печати, чтобы на бумаге или на экране она выглядела чуть приятнее.
Те же задачи, которые мы решали с помощью инструментов графического редактора, можно решать при помощи алгоритмов, где мы точно будем знать, что и как происходит с изображением. Дальше начинается медленное погружение в инженерный и научный подход к улучшению изображений. Поэтому и язык описания будет чуть строже, терминология станет чуть более жёсткой и появятся отсылки к научным публикациям, которые будут приведены в конце.

## 4 Программная реконструкция изображений — подавление шума

На исходном изображении присутствует высокочастотный шум, который желательно отфильтровать перед тем как приступить к восстановлению изображения. Алгоритм фильтрации шумов описан в работе [1]. В данном алгоритме используется два настраиваемых параметра: параметр регуляризации &lambda;&in;[0,1]  и количество итераций iter_count. При &lambda;=0 алгоритм шумоподавления сглаживает шумы сильнее, выравнивая текстурную составляющую изображения, пренебрегая контурной. При &lambda;=1 алгоритм шумоподавления сглаживает шумы слабее, но при этом сохраняет контуры на изображении. Количество итераций влияет на точность получаемого результата. В начальном приближении рекомендуется установить следующие значения: &lambda;=0.5,iter_count=300. Варьирование данных параметров позволит получить результат обработки, в котором будет найден компромисс между сглаживанием текстурной и сохранением контурной информации на зашумленном изображении.

На рисунке 4.1 изображены примеры фильтрации шумов с параметрами &lambda;=0.8,iter_count=300 и &lambda;=0.2,iter_count=300. На рисунке 4.2 приведены увеличенные фрагменты.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/4.1.jpg" width="50%" title="Обработанное изображение (0.8, 300). Исходное изображение. Обработанное изображение (0.2, 300)"/>
  
  Рисунок 4.1 – Демонстрация работы алгоритма шумоподавления, слева направо:  
  результат обработки с параметрами &lambda;=0.8,iter_count=300,  
  исходное изображение без обработки,  
  результат обработки с параметрами &lambda;=0.2,iter_count=300
</div>

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/4.2.jpg" width="50%" title="Фрагменты. Обработанное изображение (0.8, 300). Исходное изображение. Обработанное изображение (0.2, 300)"/>
  
  Рисунок 4.2 – Демонстрация работы алгоритма шумоподавления (увеличенные фрагменты), слева направо:  
  результат обработки с параметрами &lambda;=0.8,iter_count=300,  
  исходное изображение без обработки,  
  результат обработки с параметрами &lambda;=0.2,iter_count=300
</div>

На рисунке 4.2 видно, что в случае выбора параметра &lambda;=0.8 шум немного сгладился, но тем не менее его присутствие видно невооруженным взглядом. Контуры очертания материка не пострадали. На изображении, обработанным алгоритмом с заданным параметром &lambda;=0.2, от шумов не осталось и следа, однако, очертания суши значительно “смягчились”.

## 5 Программная реконструкция изображений — цветовая коррекция

Приведенные в разделе 3 базовые методы цветовой коррекции выполнены вручную в специальной программе обработки растровых изображений. Здесь мы разберём, как похожие операции выполнить используя Python, библиотеки NumPy, Matplotlib и OpenCV.
Обработку по шагам можно выполнить онлайн на платформе Google Colaboratory, используя прилагаемый блокнот (python notebook). Удобство работы с кодом на Python в Google Colaboratory заключается в том, что для работы вам даже не нужно устанавливать Python на свой компьютер. Тоже самое вы можете сделать на своём компьютере, сохранив блокнот в формате *.ipnb на локальный диск и запустив Jupyter notebook на вашем компьютере. 

[Цветовая коррекция на Python в Google Colaboratory]

Работа с  гистограммой цветного изображения позволяет существенно улучшить цветовой контраст изображения и его визуальное восприятие.
Растянутая по всему диапазону гистограмма дает более высокое визуальное качество изображения, однако график гистограммы получается более рваный. Такая «рваная» гистограмма приводит к так называемому эффекту постеризации изображения (вырождения детальности изображения), особенно сильно проявляющемуся после нейросетевой обработки или повышения чёткости изображения. Пример такой постеризации приведён ниже. 

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/5.1.jpg" width="50%" title="Постеризация изображения. Информация о мелких деталях утеряна"/>
  
  Рисунок 5.1 – Пример постеризации изображения. Информация о мелких деталях утеряна
</div>

С учетом сказанного, предпочтительным результатом обработки является сдвиг гистограммы влево с растяжением, при этом получается компромиссный вариант по улучшению цвета изображения (рисунок 5.2) с минимальным эффектом постеризации, результат приведен на рисунке 5.3.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/5.2.jpg" width="50%" title="Исходное изображение после шумоподавления"/>
  
  Рисунок 5.2 – Исходное изображение после обработки алгоритмом шумоподавления
</div>

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/5.3.jpg" width="50%" title="Результат сдвига гистограммы"/>
  
  Рисунок 5.3 – Результат сдвига гистограммы влево с растяжением
</div>

## 6 Программная реконструкция изображений — повышение чёткости

Изображения, получаемые при помощи плоских объективов, подвержены значительным хроматическим аберрациям (искажениям, определяемым цветом объектов) и сильно уступают в качестве современным многолинзовым объективам. Однако, применение вычислительной постобработки позволяет улучшить качество таких изображений.
Рассмотрим два подхода к повышению качества изображения:
Классический — применение цветовой коррекции и обратной свёртки для повышения чёткости изображения;
Нейросетевой подход — применение предварительно обученной свёрточной нейронной сети.
В данном разделе рассмотрим применение метода  обратной свёртки на основе метода минимизации полной вариации [2]. Предлагаемый подход основан на следующих этапах:
идентификация ядра размытия — функции размытия точки;
реализация обратной свёртки на основе метода минимизации полной вариации.
Получение оценки ядра размытия основано на сравнении получаемого снимка калибровочного изображения и его четкого оригинала (рисунок 6.1). Изображение калибровочной шкалы содержит белый шум, равномерное распределение интенсивностей от 0 до 255.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/6.1.jpg" width="50%" title="Шкала идентификации функции размытия точки"/>
  
  Рисунок 6.1 – Шкала идентификации функции размытия точки
</div>

Идентификация функции размытия точки осуществлялась в лаборатории перед отправкой объектива в космос. Перед применением обратной свертки с рассчитанным ядром смаза осуществляется цветовая коррекция изображения с использованием трехмерных таблиц поиска (3D LUT). Для вычисления параметров цветовой коррекции так же использовались калибровочные цветовые шкалы. Пример такой шкалы приведён на рисунке 6.2.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/6.2.jpg" width="50%" title="Цветовая калибровочная шкала"/>
  
  Рисунок 6.2 – Цветовая калибровочная шкала
</div>
 
Результат применения цветовой коррекции с использованием 3D LUT и алгоритма обратной свёртки приведён на рисунке 6.3.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/6.3.jpg" width="50%" title="Результат обработки алгоритмом обратной свертки"/>
  
  Рисунок 6.3 – Результат обработки алгоритмом обратной свертки
</div>

## 7 Нейросетевая реконструкция изображений
В данном разделе приведён пример восстановления качества изображения с помощью нейронной сети U-Net. Архитектура сети и процедура обучения описаны в работе [3]. Нейросетевая реконструкция изображений относится к области вычислительной фотографии. Ознакомление с данной темой рекомендуется начать со статьи [4]. 
На рисунке 7.1 представлено наше исходное изображение, полученное плоским дифракционным объективом и поступающее на вход нейросети.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/7.1.jpg" width="50%" title="Исходное изображение со спутника"/>
  
  Рисунок 7.1 – Пример изображения, полученного плоским дифракционным объективом
</div>

Перед обработкой нейронной сетью U-Net предлагается устранить высокочастотный шум на основе алгоритма, описанного в разделе 4 (рисунок 7.2). Также после подавления шума предлагается сдвинуть гистограмму изображения влево с растяжением (рисунок 7.3). Процедура описана в разделе 5.  Результирующее изображение подается на вход нейронной сети. На рисунке 7.4 представлен результат нейросетевой реконструкции.

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/7.2.jpg" width="50%" title="Результат шумоподавления"/>
  
  Рисунок 7.2 – Результат шумоподавления (&lambda;=0.2,iter_count=1200) 
</div>

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/7.3.jpg" width="50%" title="Результат сдвига гистограммы"/>
  
  Рисунок 7.3  – Результат сдвига гистограммы влево с растяжением
</div>

<div align="center">
  <img src="https://github.com/zenytsa/space_images/blob/main/Images/7.4.jpg" width="50%" title="Результат нейросетевой реконструкции"/>
  
  Рисунок 7.4 - Результат нейросетевой реконструкции
</div>

Чтобы самостоятельно запустить нейросетевую обработку в Google Colaboratory необходимо:

1. Перейти по [ссылке] и скопировать папку CNN_reconstruction на свой гугл-диск.
2. Открыть Jupyter notebook  cnn_reconstruction.ipynb с помощью  Google Colaboratory.
3. Далее следовать  инструкциям в cnn_reconstruction.ipynb .

## Список литературы
1. __Nikonorov, A.__ Vessel segmentation for noisy CT data with quality measure based on single-point contrast-to-noise ratio / A. Nikonorov, A. Kolsanov, M. Petrov, Y. Yuzifovich, E. Prilepin, S. Chaplygin, P. Zelter, K. Bychenkov // Communications in Computer and Information Science. – 2016. – V. 585. – P. 490-507.
2. __Heide, F.__ High-Quality Computational Imaging Through Simple Lenses / F. Heide, M. Rouf, M. B. Hullin et. al. // ACM Transactions on Graphics (TOG). – 2013. – Vol. 32, Iss. 5, No. 149.
3. __Евдокимова, В.В.__ Нейросетевая реконструкция видеопотока в дифракционных оптических системах массового производства / В.В. Евдокимова, М.В. Петров, М.А. Клюева, Е.Ю. Зыбин, В.В. Косьянчук, И.Б. Мищенко, В.М. Новиков, Н.И. Сельвесюк, Е.И. Ершов, Н.А. Ивлиев, Р.В. Скиданов, Н.Л. Казанский, А.В. Никоноров // Компьютерная оптика. – 2021. – Т. 45, № 1. – С. 130-141. – DOI: 10.18287/2412-6179-CO-834.
4. https://vas3k.ru/blog/computational_photography/

[Цветовая коррекция на Python в Google Colaboratory]: https://colab.research.google.com/drive/1KpskMYkAjXD6GrIegqB7ZT513ImnNGxD?usp=sharing
[ссылке]:https://drive.google.com/drive/folders/1h9XAsb1cHeDtjAQkFg09zaM-DTpl4uwg?usp=sharing
